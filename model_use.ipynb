{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b808e51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Warning: No valid patients found in dataset!\n",
      "Total patients to process: 0\n",
      "Model loaded successfully\n",
      "{}\n",
      "\n",
      "Warning: No metrics to summarize (all_metrics is empty)!\n",
      "\n",
      "=== Processing Complete ===\n",
      "Total patients processed: 0\n",
      "Results stored in: model_results_test\n",
      "Each patient has:\n",
      "  - Visualization image: [ID]/[ID]_visualization.png\n",
      "  - Detailed metrics: [ID]/[ID]_metrics.txt\n",
      "  - Prediction nii: [ID]/[ID]_prediction.nii.gz\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, EnsureTyped, Orientationd,\n",
    "    Spacingd, NormalizeIntensityd, Activations, AsDiscrete, MapTransform, SpatialPadd\n",
    ")\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.inferers import sliding_window_inference\n",
    "import torch.nn.functional as F\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "# 仅解决负号显示问题，无中文字体依赖\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'  # 通用无衬线字体\n",
    "\n",
    "\n",
    "class ConvertToMultiChannel5Classesd(MapTransform):\n",
    "    \"\"\"将5亚型标签转换为多通道格式\"\"\"\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            result = [\n",
    "                d[key] == 1,  # 亚型1\n",
    "                d[key] == 2,  # 亚型2\n",
    "                d[key] == 3,  # 亚型3\n",
    "                d[key] == 4,  # 亚型4\n",
    "                d[key] == 5   # 亚型5\n",
    "            ]\n",
    "            d[key] = torch.stack(result, axis=0).float()\n",
    "        return d\n",
    "\n",
    "\n",
    "class CustomCTDataset(Dataset):\n",
    "    \"\"\"CT数据集类（支持全量加载）\"\"\"\n",
    "    def __init__(self, image_dir, label_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        # 初始化image_info（关键修复：确保属性始终存在）\n",
    "        self.image_info = {}\n",
    "        self.data = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        data = []\n",
    "        patient_ids = set()\n",
    "        \n",
    "        # 提取所有有效患者ID\n",
    "        for filename in os.listdir(self.image_dir):\n",
    "            if filename.endswith(\"_head.nii.gz\"):\n",
    "                patient_id = filename.split(\"_head.nii.gz\")[0]\n",
    "                patient_ids.add(patient_id)\n",
    "        \n",
    "        # 匹配图像和标签\n",
    "        for patient_id in sorted(patient_ids):  # 排序保证处理顺序固定\n",
    "            image_path = os.path.join(self.image_dir, f\"{patient_id}_head.nii.gz\")\n",
    "            label_path = os.path.join(self.label_dir, f\"{patient_id}_merged.nii\")\n",
    "            \n",
    "            if os.path.exists(image_path) and os.path.exists(label_path):\n",
    "                try:\n",
    "                    # 读取图像信息用于后续保存nii\n",
    "                    image_itk = sitk.ReadImage(image_path)\n",
    "                    self.image_info[patient_id] = {\n",
    "                        'origin': image_itk.GetOrigin(),\n",
    "                        'spacing': image_itk.GetSpacing(),\n",
    "                        'direction': image_itk.GetDirection(),\n",
    "                        'size': image_itk.GetSize()  # 新增：保存图像尺寸\n",
    "                    }\n",
    "                    data.append({\n",
    "                        \"image\": image_path,\n",
    "                        \"label\": label_path,\n",
    "                        \"patient_id\": patient_id,\n",
    "                        \"original_image_path\": image_path  # 新增：传递原始图像路径\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Failed to read image info for patient {patient_id}: {e}, skipped\")\n",
    "            else:\n",
    "                print(f\"Warning: Incomplete data for patient {patient_id}, skipped\")\n",
    "        \n",
    "        if not data:\n",
    "            print(\"Warning: No valid patients found in dataset!\")\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        return data\n",
    "\n",
    "\n",
    "class EvaluationMetrics:\n",
    "    \"\"\"评估指标计算类\"\"\"\n",
    "    @staticmethod\n",
    "    def dice(pred, target):\n",
    "        \"\"\"计算DICE系数\"\"\"\n",
    "        intersection = np.sum(pred * target)\n",
    "        union = np.sum(pred) + np.sum(target)\n",
    "        return 2 * intersection / (union + 1e-8)\n",
    "\n",
    "    @staticmethod\n",
    "    def iou(pred, target):\n",
    "        \"\"\"计算交并比IoU\"\"\"\n",
    "        intersection = np.sum(pred * target)\n",
    "        union = np.sum(pred) + np.sum(target) - intersection\n",
    "        return intersection / (union + 1e-8)\n",
    "\n",
    "    @staticmethod\n",
    "    def hd95(pred, target, spacing):\n",
    "        \"\"\"计算95%豪斯多夫距离(mm)\"\"\"\n",
    "        if np.sum(pred) == 0 or np.sum(target) == 0:\n",
    "            return np.nan\n",
    "        \n",
    "        pred_coords = np.argwhere(pred) * spacing\n",
    "        target_coords = np.argwhere(target) * spacing\n",
    "        \n",
    "        d1 = directed_hausdorff(pred_coords, target_coords)[0]\n",
    "        d2 = directed_hausdorff(target_coords, pred_coords)[0]\n",
    "        hd = max(d1, d2)\n",
    "        \n",
    "        all_distances = []\n",
    "        for p in pred_coords:\n",
    "            min_dist = np.min(np.linalg.norm(p - target_coords, axis=1))\n",
    "            all_distances.append(min_dist)\n",
    "        for t in target_coords:\n",
    "            min_dist = np.min(np.linalg.norm(t - pred_coords, axis=1))\n",
    "            all_distances.append(min_dist)\n",
    "        \n",
    "        return np.percentile(all_distances, 95) if all_distances else np.nan\n",
    "\n",
    "    @staticmethod\n",
    "    def fp_volume(pred, target, spacing):\n",
    "        \"\"\"计算假阳性体积(mm³)\"\"\"\n",
    "        fp = np.logical_and(pred > 0, target == 0).astype(np.float32)\n",
    "        voxel_volume = np.prod(spacing)\n",
    "        return np.sum(fp) * voxel_volume\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_all_metrics(pred, target, spacing):\n",
    "        \"\"\"计算所有亚型的完整指标（仅包含标签中存在的亚型）\"\"\"\n",
    "        metrics = {\n",
    "            \"dice\": [],\n",
    "            \"iou\": [],\n",
    "            \"hd95\": [],\n",
    "            \"fp_volume\": EvaluationMetrics.fp_volume(pred, target, spacing),\n",
    "            \"present_subtypes\": []  # 记录存在的亚型\n",
    "        }\n",
    "        \n",
    "        # 找出标签中存在的亚型\n",
    "        present_subtypes = np.unique(target)\n",
    "        present_subtypes = [s for s in present_subtypes if s != 0]  # 排除背景\n",
    "        \n",
    "        for c in range(5):\n",
    "            class_idx = c + 1\n",
    "            # 只计算标签中存在的亚型\n",
    "            if class_idx in present_subtypes:\n",
    "                pred_class = (pred == class_idx).astype(np.float32)\n",
    "                target_class = (target == class_idx).astype(np.float32)\n",
    "                \n",
    "                metrics[\"dice\"].append(EvaluationMetrics.dice(pred_class, target_class))\n",
    "                metrics[\"iou\"].append(EvaluationMetrics.iou(pred_class, target_class))\n",
    "                metrics[\"hd95\"].append(EvaluationMetrics.hd95(pred_class, target_class, spacing))\n",
    "                metrics[\"present_subtypes\"].append(class_idx)\n",
    "            else:\n",
    "                # 对于不存在的亚型，不纳入计算（使用NaN标记）\n",
    "                metrics[\"dice\"].append(np.nan)\n",
    "                metrics[\"iou\"].append(np.nan)\n",
    "                metrics[\"hd95\"].append(np.nan)\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "\n",
    "def create_color_map():\n",
    "    \"\"\"创建5亚型的颜色映射（RGBA格式）\"\"\"\n",
    "    color_map = np.zeros((6, 4))  # 0=背景(透明), 1-5=亚型\n",
    "    color_map[0] = [0, 0, 0, 0]          # 背景\n",
    "    color_map[1] = [1, 0, 0, 0.7]        # 亚型1：红色\n",
    "    color_map[2] = [0, 1, 0, 0.7]        # 亚型2：绿色\n",
    "    color_map[3] = [0, 0, 1, 0.7]        # 亚型3：蓝色\n",
    "    color_map[4] = [1, 1, 0, 0.7]        # 亚型4：黄色\n",
    "    color_map[5] = [1, 0, 1, 0.7]        # 亚型5：紫色\n",
    "    return color_map\n",
    "\n",
    "\n",
    "def generate_visualization(image_3d, target_3d, pred_3d, metrics, patient_id, save_dir):\n",
    "    \"\"\"生成单例患者的可视化结果（x-y切片 + 定量指标）\"\"\"\n",
    "    # 1. 基础配置\n",
    "    color_map = create_color_map()\n",
    "    mid_slice = image_3d.shape[2] // 2  # x-y轴位切片（沿W轴中间层）\n",
    "    \n",
    "    # 2. 提取切片数据\n",
    "    image_slice = image_3d[:, :, mid_slice]\n",
    "    target_slice = target_3d[:, :, mid_slice]\n",
    "    pred_slice = pred_3d[:, :, mid_slice]\n",
    "    \n",
    "    # 3. 生成彩色标签/预测图\n",
    "    # 金标准彩色图\n",
    "    target_color = np.zeros((target_slice.shape[0], target_slice.shape[1], 4))\n",
    "    for i in range(6):\n",
    "        target_color[target_slice == i] = color_map[i]\n",
    "    \n",
    "    # 预测结果彩色图\n",
    "    pred_color = np.zeros((pred_slice.shape[0], pred_slice.shape[1], 4))\n",
    "    for i in range(6):\n",
    "        pred_color[pred_slice == i] = color_map[i]\n",
    "    \n",
    "    # 4. 创建可视化图像\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "    fig.suptitle(f\"Patient ID: {patient_id} | Axial Slice (W-axis: {mid_slice})\", fontsize=16, fontweight=\"bold\")\n",
    "    \n",
    "    # 4.1 CT原图\n",
    "    axes[0].imshow(image_slice, cmap=\"gray\", aspect=\"auto\")\n",
    "    axes[0].set_title(\"CT Original Image\", fontsize=14)\n",
    "    axes[0].axis(\"off\")\n",
    "    \n",
    "    # 4.2 金标准标签（多颜色）\n",
    "    axes[1].imshow(image_slice, cmap=\"gray\", aspect=\"auto\", alpha=0.8)\n",
    "    axes[1].imshow(target_color, aspect=\"auto\")\n",
    "    axes[1].set_title(\"Ground Truth (Color-Coded Subtypes)\", fontsize=14)\n",
    "    axes[1].axis(\"off\")\n",
    "    \n",
    "    # 4.3 模型预测结果（多颜色）\n",
    "    axes[2].imshow(image_slice, cmap=\"gray\", aspect=\"auto\", alpha=0.8)\n",
    "    axes[2].imshow(pred_color, aspect=\"auto\")\n",
    "    axes[2].set_title(\"Model Prediction (Color-Coded Subtypes)\", fontsize=14)\n",
    "    axes[2].axis(\"off\")\n",
    "    \n",
    "    # 5. 添加定量指标文本（图下方）\n",
    "    metrics_text = f\"Evaluation Metrics:\\nFP Volume: {metrics['fp_volume']:.2f} mm³\\n\"\n",
    "    # 只显示存在的亚型指标\n",
    "    for i in metrics[\"present_subtypes\"]:\n",
    "        idx = i - 1\n",
    "        metrics_text += f\"Subtype {i} - DICE: {metrics['dice'][idx]:.4f} | IoU: {metrics['iou'][idx]:.4f} | HD95: {np.nan if np.isnan(metrics['hd95'][idx]) else metrics['hd95'][idx]:.2f} mm\\n\"\n",
    "    \n",
    "    fig.text(0.05, 0.02, metrics_text, fontsize=10, verticalalignment='bottom',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 6. 添加颜色图例\n",
    "    handles = [plt.Rectangle((0, 0), 1, 1, facecolor=color_map[i][:3], alpha=color_map[i][3]) for i in range(1, 6)]\n",
    "    labels = [f\"Subtype {i}\" for i in range(1, 6)]\n",
    "    fig.legend(handles, labels, loc=\"upper right\", bbox_to_anchor=(0.98, 0.95), ncol=5, fontsize=10)\n",
    "    \n",
    "    # 7. 保存图像\n",
    "    plt.tight_layout(rect=[0.05, 0.1, 0.95, 0.95])  # 预留指标和图例空间\n",
    "    save_path = os.path.join(save_dir, f\"{patient_id}_visualization.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "\n",
    "def save_patient_metrics(patient_id, metrics, save_dir):\n",
    "    \"\"\"保存单例患者的详细指标到文件\"\"\"\n",
    "    metrics_path = os.path.join(save_dir, f\"{patient_id}_metrics.txt\")\n",
    "    with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Patient ID: {patient_id}\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(f\"False Positive Volume: {metrics['fp_volume']:.2f} mm³\\n\\n\")\n",
    "        f.write(\"Present Subtypes in Ground Truth: \" + \", \".join(map(str, metrics[\"present_subtypes\"])) + \"\\n\\n\")\n",
    "        f.write(\"Subtype-wise Metrics:\\n\")\n",
    "        # 只保存存在的亚型指标\n",
    "        for i in metrics[\"present_subtypes\"]:\n",
    "            idx = i - 1\n",
    "            f.write(f\"Subtype {i}:\\n\")\n",
    "            f.write(f\"  DICE: {metrics['dice'][idx]:.4f}\\n\")\n",
    "            f.write(f\"  IoU: {metrics['iou'][idx]:.4f}\\n\")\n",
    "            f.write(f\"  HD95: {np.nan if np.isnan(metrics['hd95'][idx]) else metrics['hd95'][idx]:.2f} mm\\n\\n\")\n",
    "    return metrics_path\n",
    "\n",
    "\n",
    "def save_prediction_as_nii(pred_3d, patient_id, dataset, save_dir):\n",
    "    \"\"\"将预测结果保存为nii格式（增加容错处理）\"\"\"\n",
    "    try:\n",
    "        # 获取原始图像的空间信息\n",
    "        if patient_id not in dataset.image_info:\n",
    "            print(f\"Warning: No image info for patient {patient_id}, using default spacing\")\n",
    "            # 使用默认空间信息（兜底方案）\n",
    "            image_info = {\n",
    "                'origin': (0.0, 0.0, 0.0),\n",
    "                'spacing': (1.0, 1.0, 1.0),\n",
    "                'direction': (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
    "            }\n",
    "        else:\n",
    "            image_info = dataset.image_info[patient_id]\n",
    "        \n",
    "        # 调整维度顺序：numpy (D,H,W) → SimpleITK (W,H,D)\n",
    "        pred_3d_transposed = np.transpose(pred_3d, (2, 1, 0))\n",
    "        \n",
    "        # 转换数据类型为整数\n",
    "        pred_itk = sitk.GetImageFromArray(pred_3d_transposed.astype(np.int16))\n",
    "        \n",
    "        # 设置空间信息（与原始图像保持一致）\n",
    "        pred_itk.SetOrigin(image_info['origin'])\n",
    "        pred_itk.SetSpacing(image_info['spacing'])\n",
    "        pred_itk.SetDirection(image_info['direction'])\n",
    "        \n",
    "        # 保存为nii文件\n",
    "        save_path = os.path.join(save_dir, f\"{patient_id}_prediction.nii.gz\")\n",
    "        sitk.WriteImage(pred_itk, save_path, useCompression=True)\n",
    "        print(f\"  Successfully saved prediction to: {save_path}\")\n",
    "        return save_path\n",
    "    except Exception as e:\n",
    "        print(f\"  Error saving nii for patient {patient_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def update_summary_file(all_metrics, summary_path):\n",
    "    \"\"\"更新全局汇总文件\"\"\"\n",
    "    with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Global Summary of All Patients\\n\")\n",
    "        f.write(\"=\"*120 + \"\\n\")\n",
    "        # 表头\n",
    "        headers = [\"Patient ID\", \"FP_Volume(mm³)\", \n",
    "                   \"S1_DICE\", \"S1_IoU\", \"S1_HD95\",\n",
    "                   \"S2_DICE\", \"S2_IoU\", \"S2_HD95\",\n",
    "                   \"S3_DICE\", \"S3_IoU\", \"S3_HD95\",\n",
    "                   \"S4_DICE\", \"S4_IoU\", \"S4_HD95\",\n",
    "                   \"S5_DICE\", \"S5_IoU\", \"S5_HD95\"]\n",
    "        f.write(\"\\t\".join(headers) + \"\\n\")\n",
    "        \n",
    "        # 逐行写入患者数据\n",
    "        for patient_id, metrics in all_metrics.items():\n",
    "            row = [\n",
    "                patient_id,\n",
    "                f\"{metrics['fp_volume']:.2f}\",\n",
    "                # 亚型1\n",
    "                f\"{metrics['dice'][0]:.4f}\" if not np.isnan(metrics['dice'][0]) else \"N/A\",\n",
    "                f\"{metrics['iou'][0]:.4f}\" if not np.isnan(metrics['iou'][0]) else \"N/A\",\n",
    "                f\"{metrics['hd95'][0]:.2f}\" if not np.isnan(metrics['hd95'][0]) else \"N/A\",\n",
    "                # 亚型2\n",
    "                f\"{metrics['dice'][1]:.4f}\" if not np.isnan(metrics['dice'][1]) else \"N/A\",\n",
    "                f\"{metrics['iou'][1]:.4f}\" if not np.isnan(metrics['iou'][1]) else \"N/A\",\n",
    "                f\"{metrics['hd95'][1]:.2f}\" if not np.isnan(metrics['hd95'][1]) else \"N/A\",\n",
    "                # 亚型3\n",
    "                f\"{metrics['dice'][2]:.4f}\" if not np.isnan(metrics['dice'][2]) else \"N/A\",\n",
    "                f\"{metrics['iou'][2]:.4f}\" if not np.isnan(metrics['iou'][2]) else \"N/A\",\n",
    "                f\"{metrics['hd95'][2]:.2f}\" if not np.isnan(metrics['hd95'][2]) else \"N/A\",\n",
    "                # 亚型4\n",
    "                f\"{metrics['dice'][3]:.4f}\" if not np.isnan(metrics['dice'][3]) else \"N/A\",\n",
    "                f\"{metrics['iou'][3]:.4f}\" if not np.isnan(metrics['iou'][3]) else \"N/A\",\n",
    "                f\"{metrics['hd95'][3]:.2f}\" if not np.isnan(metrics['hd95'][3]) else \"N/A\",\n",
    "                # 亚型5\n",
    "                f\"{metrics['dice'][4]:.4f}\" if not np.isnan(metrics['dice'][4]) else \"N/A\",\n",
    "                f\"{metrics['iou'][4]:.4f}\" if not np.isnan(metrics['iou'][4]) else \"N/A\",\n",
    "                f\"{metrics['hd95'][4]:.2f}\" if not np.isnan(metrics['hd95'][4]) else \"N/A\"\n",
    "            ]\n",
    "            f.write(\"\\t\".join(row) + \"\\n\")\n",
    "        \n",
    "        # 计算并写入平均值（仅包含存在的亚型）\n",
    "        f.write(\"\\n\" + \"=\"*120 + \"\\n\")\n",
    "        f.write(\"Average Metrics (only for present subtypes):\\n\")\n",
    "        fp_volumes = [m['fp_volume'] for m in all_metrics.values()]\n",
    "        f.write(f\"Average FP Volume: {np.mean(fp_volumes):.2f} mm³\\n\")\n",
    "        \n",
    "        for i in range(5):\n",
    "            dice_list = [m['dice'][i] for m in all_metrics.values() if not np.isnan(m['dice'][i])]\n",
    "            iou_list = [m['iou'][i] for m in all_metrics.values() if not np.isnan(m['iou'][i])]\n",
    "            hd95_list = [m['hd95'][i] for m in all_metrics.values() if not np.isnan(m['hd95'][i])]\n",
    "            \n",
    "            f.write(f\"Subtype {i+1}:\\n\")\n",
    "            f.write(f\"  Average DICE: {np.mean(dice_list):.4f} (n={len(dice_list)})\\n\" if dice_list else f\"  Average DICE: N/A (n=0)\\n\")\n",
    "            f.write(f\"  Average IoU: {np.mean(iou_list):.4f} (n={len(iou_list)})\\n\" if iou_list else f\"  Average IoU: N/A (n=0)\\n\")\n",
    "            f.write(f\"  Average HD95: {np.mean(hd95_list):.2f} mm (n={len(hd95_list)})\\n\" if hd95_list else f\"  Average HD95: N/A (n=0)\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 1. 配置参数\n",
    "    config = {\n",
    "        \"image_dir\": \"/workspace/Task04_Hippocampus/imagesTr\",\n",
    "        \"label_dir\": \"/workspace/Task04_Hippocampus/labelsTr\",\n",
    "        \"model_path\": \"/workspace/ct_models/best_model_27.pth\",\n",
    "        \"root_output_dir\": \"model_results_test\",  # 根输出目录\n",
    "        \"spacing\": (0.5, 0.5, 5),          # 图像spacing\n",
    "        \"batch_size\": 1,\n",
    "        \"num_workers\": 4\n",
    "    }\n",
    "    \n",
    "    # 2. 创建目录结构\n",
    "    os.makedirs(config[\"root_output_dir\"], exist_ok=True)\n",
    "    summary_path = os.path.join(config[\"root_output_dir\"], \"global_summary.txt\")\n",
    "    \n",
    "    # 3. 设备配置\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # 4. 数据变换\n",
    "    val_transform = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\"]),\n",
    "            EnsureChannelFirstd(keys=\"image\"),\n",
    "            EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "            ConvertToMultiChannel5Classesd(keys=\"label\"),\n",
    "            SpatialPadd(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                spatial_size=(64, 64, 64),  # (D, H, W) — divisible by 32\n",
    "                method=\"end\",\n",
    "            ),\n",
    "            #rientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "            #pacingd(\n",
    "            #   keys=[\"image\", \"label\"],\n",
    "            #   pixdim=(1.0, 1.0, 1.0),\n",
    "            #   mode=(\"bilinear\", \"nearest\"),\n",
    "            #,\n",
    "            NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 5. 加载数据集\n",
    "    dataset = CustomCTDataset(\n",
    "        image_dir=config[\"image_dir\"],\n",
    "        label_dir=config[\"label_dir\"],\n",
    "        transform=val_transform\n",
    "    )\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        num_workers=config[\"num_workers\"],\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    print(f\"Total patients to process: {len(dataset)}\")\n",
    "    \n",
    "    # 6. 初始化模型（增加容错：适配不同输入尺寸）\n",
    "    try:\n",
    "        model = SwinUNETR(\n",
    "            #img_size=(192, 192, 192),  # 显式指定输入尺寸\n",
    "            in_channels=1,\n",
    "            out_channels=5,\n",
    "            feature_size=48,\n",
    "            use_checkpoint=True if torch.cuda.is_available() else False\n",
    "        ).to(device)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to initialize SwinUNETR with img_size=(192,192,192): {e}\")\n",
    "        print(\"Trying to initialize model without explicit img_size...\")\n",
    "        model = SwinUNETR(\n",
    "            in_channels=1,\n",
    "            out_channels=5,\n",
    "            feature_size=48,\n",
    "            use_checkpoint=True if torch.cuda.is_available() else False\n",
    "        ).to(device)\n",
    "    \n",
    "    # 加载模型权重（增加容错）\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(config[\"model_path\"], map_location=device))\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Warning: Strict loading failed: {e}\")\n",
    "        print(\"Trying non-strict loading...\")\n",
    "        model.load_state_dict(torch.load(config[\"model_path\"], map_location=device), strict=False)\n",
    "    model.eval()\n",
    "    print(\"Model loaded successfully\")\n",
    "    \n",
    "    # 后处理\n",
    "    post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "    \n",
    "    # 7. 推理+可视化+指标计算（逐例处理）\n",
    "    all_metrics = {}  # 存储所有患者的指标 {patient_id: metrics}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "            patient_id = batch[\"patient_id\"][0]\n",
    "            print(f\"\\nProcessing patient {patient_id} ({idx+1}/{len(dataset)})\")\n",
    "            \n",
    "            # 创建患者专属目录\n",
    "            patient_dir = os.path.join(config[\"root_output_dir\"], patient_id)\n",
    "            os.makedirs(patient_dir, exist_ok=True)\n",
    "            \n",
    "            # 数据准备\n",
    "            image = batch[\"image\"].to(device)  # (1, 1, D, H, W)\n",
    "            label = batch[\"label\"].cpu().numpy()[0]  # (5, D, H, W)\n",
    "            original_image = image.cpu().numpy()[0, 0]  # (D, H, W) - 原始CT图像\n",
    "            \n",
    "            # 模型推理（增加容错：适配不同ROI尺寸）\n",
    "            try:\n",
    "                output = sliding_window_inference(\n",
    "                    inputs=image,\n",
    "                    roi_size=(64, 64, 32),\n",
    "                    sw_batch_size=1,\n",
    "                    predictor=model,\n",
    "                    overlap=0.5,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Sliding window with roi_size=(192,192,192) failed: {e}\")\n",
    "                print(\"Trying smaller roi_size=(96,96,96)...\")\n",
    "                output = sliding_window_inference(\n",
    "                    inputs=image,\n",
    "                    roi_size=(96, 96, 32),\n",
    "                    sw_batch_size=1,\n",
    "                    predictor=model,\n",
    "                    overlap=0.5,\n",
    "                )\n",
    "            \n",
    "            output = post_trans(output).cpu().numpy()[0]  # (5, D, H, W)\n",
    "            \n",
    "            # 转换为单通道标签（1-5=亚型，0=背景）\n",
    "            pred_3d = np.argmax(output, axis=0) + 1\n",
    "            pred_3d[np.sum(output, axis=0) < 0.5] = 0\n",
    "            target_3d = np.argmax(label, axis=0) + 1\n",
    "            target_3d[np.sum(label, axis=0) < 0.5] = 0\n",
    "            \n",
    "            # 计算定量指标（仅包含标签中存在的亚型）\n",
    "            metrics = EvaluationMetrics.calculate_all_metrics(\n",
    "                pred=pred_3d,\n",
    "                target=target_3d,\n",
    "                spacing=config[\"spacing\"]\n",
    "            )\n",
    "            \n",
    "            all_metrics[patient_id] = metrics\n",
    "            \n",
    "            # 生成可视化\n",
    "            vis_path = generate_visualization(\n",
    "                image_3d=original_image,\n",
    "                target_3d=target_3d,\n",
    "                pred_3d=pred_3d,\n",
    "                metrics=metrics,\n",
    "                patient_id=patient_id,\n",
    "                save_dir=patient_dir\n",
    "            )\n",
    "            \n",
    "            # 保存患者详细指标\n",
    "            metrics_path = save_patient_metrics(patient_id, metrics, patient_dir)\n",
    "            \n",
    "            # 保存预测结果为nii文件\n",
    "            nii_path = save_prediction_as_nii(\n",
    "                pred_3d=pred_3d,\n",
    "                patient_id=patient_id,\n",
    "                dataset=dataset,\n",
    "                save_dir=patient_dir\n",
    "            )\n",
    "            \n",
    "            print(f\"  Visualization saved to: {vis_path}\")\n",
    "            print(f\"  Metrics saved to: {metrics_path}\")\n",
    "            if nii_path:\n",
    "                print(f\"  Prediction saved to: {nii_path}\")\n",
    "    \n",
    "    # 8. 生成全局汇总文件（增加容错：空数据处理）\n",
    "    print(all_metrics)\n",
    "    if all_metrics:\n",
    "        update_summary_file(all_metrics, summary_path)\n",
    "        print(f\"\\nGlobal summary saved to: {summary_path}\")\n",
    "    else:\n",
    "        print(\"\\nWarning: No metrics to summarize (all_metrics is empty)!\")\n",
    "    \n",
    "    # 9. 输出最终统计\n",
    "    print(\"\\n=== Processing Complete ===\")\n",
    "    print(f\"Total patients processed: {len(all_metrics)}\")\n",
    "    print(f\"Results stored in: {config['root_output_dir']}\")\n",
    "    print(f\"Each patient has:\")\n",
    "    print(f\"  - Visualization image: [ID]/[ID]_visualization.png\")\n",
    "    print(f\"  - Detailed metrics: [ID]/[ID]_metrics.txt\")\n",
    "    print(f\"  - Prediction nii: [ID]/[ID]_prediction.nii.gz\")\n",
    "    if all_metrics:\n",
    "        print(f\"Global summary: {summary_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc425cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Checking if image directory exists: True\n",
      "Checking if label directory exists: True\n",
      "Found 24 image files and 24 label files\n",
      "Found 24 unique image patients and 24 unique label patients\n",
      "Common patients found: 24\n",
      "  Loaded: hippocampus_001 (image: hippocampus_001.nii.gz, label: hippocampus_001.nii.gz)\n",
      "  Loaded: hippocampus_003 (image: hippocampus_003.nii.gz, label: hippocampus_003.nii.gz)\n",
      "  Loaded: hippocampus_004 (image: hippocampus_004.nii.gz, label: hippocampus_004.nii.gz)\n",
      "  Loaded: hippocampus_006 (image: hippocampus_006.nii.gz, label: hippocampus_006.nii.gz)\n",
      "  Loaded: hippocampus_007 (image: hippocampus_007.nii.gz, label: hippocampus_007.nii.gz)\n",
      "  Loaded: hippocampus_008 (image: hippocampus_008.nii.gz, label: hippocampus_008.nii.gz)\n",
      "  Loaded: hippocampus_011 (image: hippocampus_011.nii.gz, label: hippocampus_011.nii.gz)\n",
      "  Loaded: hippocampus_014 (image: hippocampus_014.nii.gz, label: hippocampus_014.nii.gz)\n",
      "  Loaded: hippocampus_015 (image: hippocampus_015.nii.gz, label: hippocampus_015.nii.gz)\n",
      "  Loaded: hippocampus_017 (image: hippocampus_017.nii.gz, label: hippocampus_017.nii.gz)\n",
      "  Loaded: hippocampus_019 (image: hippocampus_019.nii.gz, label: hippocampus_019.nii.gz)\n",
      "  Loaded: hippocampus_020 (image: hippocampus_020.nii.gz, label: hippocampus_020.nii.gz)\n",
      "  Loaded: hippocampus_023 (image: hippocampus_023.nii.gz, label: hippocampus_023.nii.gz)\n",
      "  Loaded: hippocampus_024 (image: hippocampus_024.nii.gz, label: hippocampus_024.nii.gz)\n",
      "  Loaded: hippocampus_025 (image: hippocampus_025.nii.gz, label: hippocampus_025.nii.gz)\n",
      "  Loaded: hippocampus_026 (image: hippocampus_026.nii.gz, label: hippocampus_026.nii.gz)\n",
      "  Loaded: hippocampus_033 (image: hippocampus_033.nii.gz, label: hippocampus_033.nii.gz)\n",
      "  Loaded: hippocampus_034 (image: hippocampus_034.nii.gz, label: hippocampus_034.nii.gz)\n",
      "  Loaded: hippocampus_035 (image: hippocampus_035.nii.gz, label: hippocampus_035.nii.gz)\n",
      "  Loaded: hippocampus_036 (image: hippocampus_036.nii.gz, label: hippocampus_036.nii.gz)\n",
      "  Loaded: hippocampus_037 (image: hippocampus_037.nii.gz, label: hippocampus_037.nii.gz)\n",
      "  Loaded: hippocampus_038 (image: hippocampus_038.nii.gz, label: hippocampus_038.nii.gz)\n",
      "  Loaded: hippocampus_039 (image: hippocampus_039.nii.gz, label: hippocampus_039.nii.gz)\n",
      "  Loaded: hippocampus_040 (image: hippocampus_040.nii.gz, label: hippocampus_040.nii.gz)\n",
      "Total valid patients loaded: 24\n",
      "Image directory contents: ['hippocampus_001.nii.gz', 'hippocampus_003.nii.gz', 'hippocampus_004.nii.gz', 'hippocampus_006.nii.gz', 'hippocampus_007.nii.gz', 'hippocampus_008.nii.gz', 'hippocampus_011.nii.gz', 'hippocampus_014.nii.gz', 'hippocampus_015.nii.gz', 'hippocampus_017.nii.gz', 'hippocampus_019.nii.gz', 'hippocampus_020.nii.gz', 'hippocampus_023.nii.gz', 'hippocampus_024.nii.gz', 'hippocampus_025.nii.gz', 'hippocampus_026.nii.gz', 'hippocampus_033.nii.gz', 'hippocampus_034.nii.gz', 'hippocampus_035.nii.gz', 'hippocampus_036.nii.gz', 'hippocampus_037.nii.gz', 'hippocampus_038.nii.gz', 'hippocampus_039.nii.gz', 'hippocampus_040.nii.gz']\n",
      "Label directory contents: ['hippocampus_001.nii.gz', 'hippocampus_003.nii.gz', 'hippocampus_004.nii.gz', 'hippocampus_006.nii.gz', 'hippocampus_007.nii.gz', 'hippocampus_008.nii.gz', 'hippocampus_011.nii.gz', 'hippocampus_014.nii.gz', 'hippocampus_015.nii.gz', 'hippocampus_017.nii.gz', 'hippocampus_019.nii.gz', 'hippocampus_020.nii.gz', 'hippocampus_023.nii.gz', 'hippocampus_024.nii.gz', 'hippocampus_025.nii.gz', 'hippocampus_026.nii.gz', 'hippocampus_033.nii.gz', 'hippocampus_034.nii.gz', 'hippocampus_035.nii.gz', 'hippocampus_036.nii.gz', 'hippocampus_037.nii.gz', 'hippocampus_038.nii.gz', 'hippocampus_039.nii.gz', 'hippocampus_040.nii.gz']\n",
      "Total patients to process: 24\n",
      "Warning: Failed to initialize SwinUNETR with img_size=(192,192,192): SwinUNETR.__init__() got an unexpected keyword argument 'img_size'\n",
      "Trying to initialize model without explicit img_size...\n",
      "Model loaded successfully with strict=True\n",
      "\n",
      "Processing patient hippocampus_001 (1/24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.12/site-packages/monai/inferers/utils.py:231: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "  win_data = inputs[unravel_slice[0]].to(sw_device)\n",
      "/venv/main/lib/python3.12/site-packages/monai/inferers/utils.py:370: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "  out[idx_zm] += p\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successfully saved prediction to: model_results_test/hippocampus_001/hippocampus_001_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_001/hippocampus_001_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_001/hippocampus_001_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_001/hippocampus_001_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_003 (2/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_003/hippocampus_003_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_003/hippocampus_003_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_003/hippocampus_003_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_003/hippocampus_003_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_004 (3/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_004/hippocampus_004_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_004/hippocampus_004_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_004/hippocampus_004_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_004/hippocampus_004_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_006 (4/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_006/hippocampus_006_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_006/hippocampus_006_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_006/hippocampus_006_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_006/hippocampus_006_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_007 (5/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_007/hippocampus_007_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_007/hippocampus_007_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_007/hippocampus_007_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_007/hippocampus_007_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_008 (6/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_008/hippocampus_008_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_008/hippocampus_008_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_008/hippocampus_008_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_008/hippocampus_008_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_011 (7/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_011/hippocampus_011_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_011/hippocampus_011_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_011/hippocampus_011_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_011/hippocampus_011_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_014 (8/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_014/hippocampus_014_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_014/hippocampus_014_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_014/hippocampus_014_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_014/hippocampus_014_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_015 (9/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_015/hippocampus_015_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_015/hippocampus_015_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_015/hippocampus_015_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_015/hippocampus_015_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_017 (10/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_017/hippocampus_017_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_017/hippocampus_017_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_017/hippocampus_017_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_017/hippocampus_017_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_019 (11/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_019/hippocampus_019_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_019/hippocampus_019_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_019/hippocampus_019_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_019/hippocampus_019_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_020 (12/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_020/hippocampus_020_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_020/hippocampus_020_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_020/hippocampus_020_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_020/hippocampus_020_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_023 (13/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_023/hippocampus_023_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_023/hippocampus_023_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_023/hippocampus_023_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_023/hippocampus_023_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_024 (14/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_024/hippocampus_024_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_024/hippocampus_024_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_024/hippocampus_024_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_024/hippocampus_024_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_025 (15/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_025/hippocampus_025_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_025/hippocampus_025_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_025/hippocampus_025_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_025/hippocampus_025_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_026 (16/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_026/hippocampus_026_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_026/hippocampus_026_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_026/hippocampus_026_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_026/hippocampus_026_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_033 (17/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_033/hippocampus_033_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_033/hippocampus_033_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_033/hippocampus_033_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_033/hippocampus_033_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_034 (18/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_034/hippocampus_034_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_034/hippocampus_034_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_034/hippocampus_034_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_034/hippocampus_034_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_035 (19/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_035/hippocampus_035_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_035/hippocampus_035_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_035/hippocampus_035_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_035/hippocampus_035_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_036 (20/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_036/hippocampus_036_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_036/hippocampus_036_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_036/hippocampus_036_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_036/hippocampus_036_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_037 (21/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_037/hippocampus_037_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_037/hippocampus_037_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_037/hippocampus_037_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_037/hippocampus_037_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_038 (22/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_038/hippocampus_038_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_038/hippocampus_038_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_038/hippocampus_038_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_038/hippocampus_038_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_039 (23/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_039/hippocampus_039_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_039/hippocampus_039_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_039/hippocampus_039_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_039/hippocampus_039_prediction.nii.gz\n",
      "\n",
      "Processing patient hippocampus_040 (24/24)\n",
      "  Successfully saved prediction to: model_results_test/hippocampus_040/hippocampus_040_prediction.nii.gz\n",
      "  Visualization saved to: model_results_test/hippocampus_040/hippocampus_040_visualization.png\n",
      "  Metrics saved to: model_results_test/hippocampus_040/hippocampus_040_metrics.txt\n",
      "  Prediction saved to: model_results_test/hippocampus_040/hippocampus_040_prediction.nii.gz\n",
      "\n",
      "Global summary saved to: model_results_test/global_summary.txt\n",
      "\n",
      "=== Processing Complete ===\n",
      "Total patients processed: 24\n",
      "Results stored in: model_results_test\n",
      "Each patient has:\n",
      "  - Visualization image: [ID]/[ID]_visualization.png\n",
      "  - Detailed metrics: [ID]/[ID]_metrics.txt\n",
      "  - Prediction nii: [ID]/[ID]_prediction.nii.gz\n",
      "Global summary: model_results_test/global_summary.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, EnsureTyped, Orientationd,\n",
    "    Spacingd, NormalizeIntensityd, Activations, AsDiscrete, MapTransform, SpatialPadd\n",
    ")\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.inferers import sliding_window_inference\n",
    "import torch.nn.functional as F\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "# Only solve minus sign display issue, no Chinese font dependency\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'  # Universal sans-serif font\n",
    "\n",
    "\n",
    "class ConvertToMultiChannel5Classesd(MapTransform):\n",
    "    \"\"\"Convert 5 subtype labels to multi-channel format\"\"\"\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            result = [\n",
    "                d[key] == 1,  # Subtype 1\n",
    "                d[key] == 2,  # Subtype 2\n",
    "                d[key] == 3,  # Subtype 3\n",
    "                d[key] == 4,  # Subtype 4\n",
    "                d[key] == 5   # Subtype 5\n",
    "            ]\n",
    "            d[key] = torch.stack(result, axis=0).float()\n",
    "        return d\n",
    "\n",
    "\n",
    "class CustomCTDataset(Dataset):\n",
    "    \"\"\"CT Dataset class (supports full loading)\"\"\"\n",
    "    def __init__(self, image_dir, label_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.image_info = {}\n",
    "        self.data = self._load_data()\n",
    "        \n",
    "        # Debug: Print directory contents\n",
    "        print(f\"Image directory contents: {os.listdir(self.image_dir)}\")\n",
    "        print(f\"Label directory contents: {os.listdir(self.label_dir)}\")\n",
    "\n",
    "    def _load_data(self):\n",
    "        data = []\n",
    "        \n",
    "        # Get all files in image directory\n",
    "        image_files = [f for f in os.listdir(self.image_dir) \n",
    "                      if f.endswith('.nii') or f.endswith('.nii.gz')]\n",
    "        \n",
    "        # Get all files in label directory\n",
    "        label_files = [f for f in os.listdir(self.label_dir) \n",
    "                      if f.endswith('.nii') or f.endswith('.nii.gz')]\n",
    "        \n",
    "        print(f\"Found {len(image_files)} image files and {len(label_files)} label files\")\n",
    "        \n",
    "        # Create mapping of patient IDs to files (more flexible approach)\n",
    "        image_dict = {}\n",
    "        for img_file in image_files:\n",
    "            # Try to extract patient ID (remove common suffixes)\n",
    "            patient_id = img_file\n",
    "            for suffix in ['_head.nii.gz', '_head.nii', '.nii.gz', '.nii']:\n",
    "                if patient_id.endswith(suffix):\n",
    "                    patient_id = patient_id.replace(suffix, '')\n",
    "                    break\n",
    "            image_dict[patient_id] = img_file\n",
    "        \n",
    "        label_dict = {}\n",
    "        for lbl_file in label_files:\n",
    "            # Try to extract patient ID (remove common suffixes)\n",
    "            patient_id = lbl_file\n",
    "            for suffix in ['_merged.nii', '_merged.nii.gz', '_label.nii', \n",
    "                          '_label.nii.gz', '.nii.gz', '.nii']:\n",
    "                if patient_id.endswith(suffix):\n",
    "                    patient_id = patient_id.replace(suffix, '')\n",
    "                    break\n",
    "            label_dict[patient_id] = lbl_file\n",
    "        \n",
    "        print(f\"Found {len(image_dict)} unique image patients and {len(label_dict)} unique label patients\")\n",
    "        \n",
    "        # Find common patient IDs\n",
    "        common_patients = set(image_dict.keys()) & set(label_dict.keys())\n",
    "        print(f\"Common patients found: {len(common_patients)}\")\n",
    "        \n",
    "        if not common_patients:\n",
    "            print(\"ERROR: No matching patients found between image and label directories!\")\n",
    "            print(f\"Image patient IDs: {list(image_dict.keys())[:5]}...\")\n",
    "            print(f\"Label patient IDs: {list(label_dict.keys())[:5]}...\")\n",
    "            return data\n",
    "        \n",
    "        # Process each common patient\n",
    "        for patient_id in sorted(common_patients):\n",
    "            image_path = os.path.join(self.image_dir, image_dict[patient_id])\n",
    "            label_path = os.path.join(self.label_dir, label_dict[patient_id])\n",
    "            \n",
    "            try:\n",
    "                # Read image for metadata\n",
    "                image_itk = sitk.ReadImage(image_path)\n",
    "                self.image_info[patient_id] = {\n",
    "                    'origin': image_itk.GetOrigin(),\n",
    "                    'spacing': image_itk.GetSpacing(),\n",
    "                    'direction': image_itk.GetDirection(),\n",
    "                    'size': image_itk.GetSize()\n",
    "                }\n",
    "                \n",
    "                data.append({\n",
    "                    \"image\": image_path,\n",
    "                    \"label\": label_path,\n",
    "                    \"patient_id\": patient_id,\n",
    "                    \"original_image_path\": image_path\n",
    "                })\n",
    "                \n",
    "                print(f\"  Loaded: {patient_id} (image: {image_dict[patient_id]}, label: {label_dict[patient_id]})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Failed to read image info for patient {patient_id}: {e}\")\n",
    "        \n",
    "        print(f\"Total valid patients loaded: {len(data)}\")\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        return data\n",
    "\n",
    "\n",
    "class EvaluationMetrics:\n",
    "    \"\"\"Evaluation metrics calculation class\"\"\"\n",
    "    @staticmethod\n",
    "    def dice(pred, target):\n",
    "        \"\"\"Calculate DICE coefficient\"\"\"\n",
    "        intersection = np.sum(pred * target)\n",
    "        union = np.sum(pred) + np.sum(target)\n",
    "        return 2 * intersection / (union + 1e-8)\n",
    "\n",
    "    @staticmethod\n",
    "    def iou(pred, target):\n",
    "        \"\"\"Calculate Intersection over Union (IoU)\"\"\"\n",
    "        intersection = np.sum(pred * target)\n",
    "        union = np.sum(pred) + np.sum(target) - intersection\n",
    "        return intersection / (union + 1e-8)\n",
    "\n",
    "    @staticmethod\n",
    "    def hd95(pred, target, spacing):\n",
    "        \"\"\"Calculate 95% Hausdorff Distance (mm)\"\"\"\n",
    "        if np.sum(pred) == 0 or np.sum(target) == 0:\n",
    "            return np.nan\n",
    "        \n",
    "        pred_coords = np.argwhere(pred) * spacing\n",
    "        target_coords = np.argwhere(target) * spacing\n",
    "        \n",
    "        d1 = directed_hausdorff(pred_coords, target_coords)[0]\n",
    "        d2 = directed_hausdorff(target_coords, pred_coords)[0]\n",
    "        hd = max(d1, d2)\n",
    "        \n",
    "        all_distances = []\n",
    "        for p in pred_coords:\n",
    "            min_dist = np.min(np.linalg.norm(p - target_coords, axis=1))\n",
    "            all_distances.append(min_dist)\n",
    "        for t in target_coords:\n",
    "            min_dist = np.min(np.linalg.norm(t - pred_coords, axis=1))\n",
    "            all_distances.append(min_dist)\n",
    "        \n",
    "        return np.percentile(all_distances, 95) if all_distances else np.nan\n",
    "\n",
    "    @staticmethod\n",
    "    def fp_volume(pred, target, spacing):\n",
    "        \"\"\"Calculate false positive volume (mm³)\"\"\"\n",
    "        fp = np.logical_and(pred > 0, target == 0).astype(np.float32)\n",
    "        voxel_volume = np.prod(spacing)\n",
    "        return np.sum(fp) * voxel_volume\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_all_metrics(pred, target, spacing):\n",
    "        \"\"\"Calculate all metrics for all subtypes (only for subtypes present in labels)\"\"\"\n",
    "        metrics = {\n",
    "            \"dice\": [],\n",
    "            \"iou\": [],\n",
    "            \"hd95\": [],\n",
    "            \"fp_volume\": EvaluationMetrics.fp_volume(pred, target, spacing),\n",
    "            \"present_subtypes\": []  # Record existing subtypes\n",
    "        }\n",
    "        \n",
    "        # Find subtypes present in labels\n",
    "        present_subtypes = np.unique(target)\n",
    "        present_subtypes = [s for s in present_subtypes if s != 0]  # Exclude background\n",
    "        \n",
    "        for c in range(5):\n",
    "            class_idx = c + 1\n",
    "            # Only calculate for subtypes present in labels\n",
    "            if class_idx in present_subtypes:\n",
    "                pred_class = (pred == class_idx).astype(np.float32)\n",
    "                target_class = (target == class_idx).astype(np.float32)\n",
    "                \n",
    "                metrics[\"dice\"].append(EvaluationMetrics.dice(pred_class, target_class))\n",
    "                metrics[\"iou\"].append(EvaluationMetrics.iou(pred_class, target_class))\n",
    "                metrics[\"hd95\"].append(EvaluationMetrics.hd95(pred_class, target_class, spacing))\n",
    "                metrics[\"present_subtypes\"].append(class_idx)\n",
    "            else:\n",
    "                # For non-existing subtypes, don't include in calculation (marked with NaN)\n",
    "                metrics[\"dice\"].append(np.nan)\n",
    "                metrics[\"iou\"].append(np.nan)\n",
    "                metrics[\"hd95\"].append(np.nan)\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "\n",
    "def create_color_map():\n",
    "    \"\"\"Create color map for 5 subtypes (RGBA format)\"\"\"\n",
    "    color_map = np.zeros((6, 4))  # 0=background(transparent), 1-5=subtypes\n",
    "    color_map[0] = [0, 0, 0, 0]          # Background\n",
    "    color_map[1] = [1, 0, 0, 0.7]        # Subtype 1: Red\n",
    "    color_map[2] = [0, 1, 0, 0.7]        # Subtype 2: Green\n",
    "    color_map[3] = [0, 0, 1, 0.7]        # Subtype 3: Blue\n",
    "    color_map[4] = [1, 1, 0, 0.7]        # Subtype 4: Yellow\n",
    "    color_map[5] = [1, 0, 1, 0.7]        # Subtype 5: Purple\n",
    "    return color_map\n",
    "\n",
    "\n",
    "def generate_visualization(image_3d, target_3d, pred_3d, metrics, patient_id, save_dir):\n",
    "    \"\"\"Generate visualization results for single patient (x-y slice + quantitative metrics)\"\"\"\n",
    "    # 1. Basic configuration\n",
    "    color_map = create_color_map()\n",
    "    mid_slice = image_3d.shape[2] // 2  # x-y axial slice (middle layer along W axis)\n",
    "    \n",
    "    # 2. Extract slice data\n",
    "    image_slice = image_3d[:, :, mid_slice]\n",
    "    target_slice = target_3d[:, :, mid_slice]\n",
    "    pred_slice = pred_3d[:, :, mid_slice]\n",
    "    \n",
    "    # 3. Generate colored label/prediction maps\n",
    "    # Ground truth color map\n",
    "    target_color = np.zeros((target_slice.shape[0], target_slice.shape[1], 4))\n",
    "    for i in range(6):\n",
    "        target_color[target_slice == i] = color_map[i]\n",
    "    \n",
    "    # Prediction color map\n",
    "    pred_color = np.zeros((pred_slice.shape[0], pred_slice.shape[1], 4))\n",
    "    for i in range(6):\n",
    "        pred_color[pred_slice == i] = color_map[i]\n",
    "    \n",
    "    # 4. Create visualization image\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "    fig.suptitle(f\"Patient ID: {patient_id} | Axial Slice (W-axis: {mid_slice})\", fontsize=16, fontweight=\"bold\")\n",
    "    \n",
    "    # 4.1 Original CT image\n",
    "    axes[0].imshow(image_slice, cmap=\"gray\", aspect=\"auto\")\n",
    "    axes[0].set_title(\"CT Original Image\", fontsize=14)\n",
    "    axes[0].axis(\"off\")\n",
    "    \n",
    "    # 4.2 Ground truth label (multi-color)\n",
    "    axes[1].imshow(image_slice, cmap=\"gray\", aspect=\"auto\", alpha=0.8)\n",
    "    axes[1].imshow(target_color, aspect=\"auto\")\n",
    "    axes[1].set_title(\"Ground Truth (Color-Coded Subtypes)\", fontsize=14)\n",
    "    axes[1].axis(\"off\")\n",
    "    \n",
    "    # 4.3 Model prediction (multi-color)\n",
    "    axes[2].imshow(image_slice, cmap=\"gray\", aspect=\"auto\", alpha=0.8)\n",
    "    axes[2].imshow(pred_color, aspect=\"auto\")\n",
    "    axes[2].set_title(\"Model Prediction (Color-Coded Subtypes)\", fontsize=14)\n",
    "    axes[2].axis(\"off\")\n",
    "    \n",
    "    # 5. Add quantitative metrics text (below image)\n",
    "    metrics_text = f\"Evaluation Metrics:\\nFP Volume: {metrics['fp_volume']:.2f} mm³\\n\"\n",
    "    # Only show metrics for existing subtypes\n",
    "    for i in metrics[\"present_subtypes\"]:\n",
    "        idx = i - 1\n",
    "        metrics_text += f\"Subtype {i} - DICE: {metrics['dice'][idx]:.4f} | IoU: {metrics['iou'][idx]:.4f} | HD95: {np.nan if np.isnan(metrics['hd95'][idx]) else metrics['hd95'][idx]:.2f} mm\\n\"\n",
    "    \n",
    "    fig.text(0.05, 0.02, metrics_text, fontsize=10, verticalalignment='bottom',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 6. Add color legend\n",
    "    handles = [plt.Rectangle((0, 0), 1, 1, facecolor=color_map[i][:3], alpha=color_map[i][3]) for i in range(1, 6)]\n",
    "    labels = [f\"Subtype {i}\" for i in range(1, 6)]\n",
    "    fig.legend(handles, labels, loc=\"upper right\", bbox_to_anchor=(0.98, 0.95), ncol=5, fontsize=10)\n",
    "    \n",
    "    # 7. Save image\n",
    "    plt.tight_layout(rect=[0.05, 0.1, 0.95, 0.95])  # Reserve space for metrics and legend\n",
    "    save_path = os.path.join(save_dir, f\"{patient_id}_visualization.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "\n",
    "def save_patient_metrics(patient_id, metrics, save_dir):\n",
    "    \"\"\"Save detailed metrics for single patient to file\"\"\"\n",
    "    metrics_path = os.path.join(save_dir, f\"{patient_id}_metrics.txt\")\n",
    "    with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Patient ID: {patient_id}\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(f\"False Positive Volume: {metrics['fp_volume']:.2f} mm³\\n\\n\")\n",
    "        f.write(\"Present Subtypes in Ground Truth: \" + \", \".join(map(str, metrics[\"present_subtypes\"])) + \"\\n\\n\")\n",
    "        f.write(\"Subtype-wise Metrics:\\n\")\n",
    "        # Only save metrics for existing subtypes\n",
    "        for i in metrics[\"present_subtypes\"]:\n",
    "            idx = i - 1\n",
    "            f.write(f\"Subtype {i}:\\n\")\n",
    "            f.write(f\"  DICE: {metrics['dice'][idx]:.4f}\\n\")\n",
    "            f.write(f\"  IoU: {metrics['iou'][idx]:.4f}\\n\")\n",
    "            f.write(f\"  HD95: {np.nan if np.isnan(metrics['hd95'][idx]) else metrics['hd95'][idx]:.2f} mm\\n\\n\")\n",
    "    return metrics_path\n",
    "\n",
    "\n",
    "def save_prediction_as_nii(pred_3d, patient_id, dataset, save_dir):\n",
    "    \"\"\"Save prediction results as nii format (with error handling)\"\"\"\n",
    "    try:\n",
    "        # Get spatial information from original image\n",
    "        if patient_id not in dataset.image_info:\n",
    "            print(f\"Warning: No image info for patient {patient_id}, using default spacing\")\n",
    "            # Use default spatial information (fallback)\n",
    "            image_info = {\n",
    "                'origin': (0.0, 0.0, 0.0),\n",
    "                'spacing': (1.0, 1.0, 1.0),\n",
    "                'direction': (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
    "            }\n",
    "        else:\n",
    "            image_info = dataset.image_info[patient_id]\n",
    "        \n",
    "        # Adjust dimension order: numpy (D,H,W) → SimpleITK (W,H,D)\n",
    "        pred_3d_transposed = np.transpose(pred_3d, (2, 1, 0))\n",
    "        \n",
    "        # Convert data type to integer\n",
    "        pred_itk = sitk.GetImageFromArray(pred_3d_transposed.astype(np.int16))\n",
    "        \n",
    "        # Set spatial information (consistent with original image)\n",
    "        pred_itk.SetOrigin(image_info['origin'])\n",
    "        pred_itk.SetSpacing(image_info['spacing'])\n",
    "        pred_itk.SetDirection(image_info['direction'])\n",
    "        \n",
    "        # Save as nii file\n",
    "        save_path = os.path.join(save_dir, f\"{patient_id}_prediction.nii.gz\")\n",
    "        sitk.WriteImage(pred_itk, save_path, useCompression=True)\n",
    "        print(f\"  Successfully saved prediction to: {save_path}\")\n",
    "        return save_path\n",
    "    except Exception as e:\n",
    "        print(f\"  Error saving nii for patient {patient_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def update_summary_file(all_metrics, summary_path):\n",
    "    \"\"\"Update global summary file\"\"\"\n",
    "    with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Global Summary of All Patients\\n\")\n",
    "        f.write(\"=\"*120 + \"\\n\")\n",
    "        # Header\n",
    "        headers = [\"Patient ID\", \"FP_Volume(mm³)\", \n",
    "                   \"S1_DICE\", \"S1_IoU\", \"S1_HD95\",\n",
    "                   \"S2_DICE\", \"S2_IoU\", \"S2_HD95\",\n",
    "                   \"S3_DICE\", \"S3_IoU\", \"S3_HD95\",\n",
    "                   \"S4_DICE\", \"S4_IoU\", \"S4_HD95\",\n",
    "                   \"S5_DICE\", \"S5_IoU\", \"S5_HD95\"]\n",
    "        f.write(\"\\t\".join(headers) + \"\\n\")\n",
    "        \n",
    "        # Write patient data row by row\n",
    "        for patient_id, metrics in all_metrics.items():\n",
    "            row = [\n",
    "                patient_id,\n",
    "                f\"{metrics['fp_volume']:.2f}\",\n",
    "                # Subtype 1\n",
    "                f\"{metrics['dice'][0]:.4f}\" if not np.isnan(metrics['dice'][0]) else \"N/A\",\n",
    "                f\"{metrics['iou'][0]:.4f}\" if not np.isnan(metrics['iou'][0]) else \"N/A\",\n",
    "                f\"{metrics['hd95'][0]:.2f}\" if not np.isnan(metrics['hd95'][0]) else \"N/A\",\n",
    "                # Subtype 2\n",
    "                f\"{metrics['dice'][1]:.4f}\" if not np.isnan(metrics['dice'][1]) else \"N/A\",\n",
    "                f\"{metrics['iou'][1]:.4f}\" if not np.isnan(metrics['iou'][1]) else \"N/A\",\n",
    "                f\"{metrics['hd95'][1]:.2f}\" if not np.isnan(metrics['hd95'][1]) else \"N/A\",\n",
    "                # Subtype 3\n",
    "                f\"{metrics['dice'][2]:.4f}\" if not np.isnan(metrics['dice'][2]) else \"N/A\",\n",
    "                f\"{metrics['iou'][2]:.4f}\" if not np.isnan(metrics['iou'][2]) else \"N/A\",\n",
    "                f\"{metrics['hd95'][2]:.2f}\" if not np.isnan(metrics['hd95'][2]) else \"N/A\",\n",
    "                # Subtype 4\n",
    "                f\"{metrics['dice'][3]:.4f}\" if not np.isnan(metrics['dice'][3]) else \"N/A\",\n",
    "                f\"{metrics['iou'][3]:.4f}\" if not np.isnan(metrics['iou'][3]) else \"N/A\",\n",
    "                f\"{metrics['hd95'][3]:.2f}\" if not np.isnan(metrics['hd95'][3]) else \"N/A\",\n",
    "                # Subtype 5\n",
    "                f\"{metrics['dice'][4]:.4f}\" if not np.isnan(metrics['dice'][4]) else \"N/A\",\n",
    "                f\"{metrics['iou'][4]:.4f}\" if not np.isnan(metrics['iou'][4]) else \"N/A\",\n",
    "                f\"{metrics['hd95'][4]:.2f}\" if not np.isnan(metrics['hd95'][4]) else \"N/A\"\n",
    "            ]\n",
    "            f.write(\"\\t\".join(row) + \"\\n\")\n",
    "        \n",
    "        # Calculate and write averages (only for existing subtypes)\n",
    "        f.write(\"\\n\" + \"=\"*120 + \"\\n\")\n",
    "        f.write(\"Average Metrics (only for present subtypes):\\n\")\n",
    "        fp_volumes = [m['fp_volume'] for m in all_metrics.values()]\n",
    "        f.write(f\"Average FP Volume: {np.mean(fp_volumes):.2f} mm³\\n\")\n",
    "        \n",
    "        for i in range(5):\n",
    "            dice_list = [m['dice'][i] for m in all_metrics.values() if not np.isnan(m['dice'][i])]\n",
    "            iou_list = [m['iou'][i] for m in all_metrics.values() if not np.isnan(m['iou'][i])]\n",
    "            hd95_list = [m['hd95'][i] for m in all_metrics.values() if not np.isnan(m['hd95'][i])]\n",
    "            \n",
    "            f.write(f\"Subtype {i+1}:\\n\")\n",
    "            f.write(f\"  Average DICE: {np.mean(dice_list):.4f} (n={len(dice_list)})\\n\" if dice_list else f\"  Average DICE: N/A (n=0)\\n\")\n",
    "            f.write(f\"  Average IoU: {np.mean(iou_list):.4f} (n={len(iou_list)})\\n\" if iou_list else f\"  Average IoU: N/A (n=0)\\n\")\n",
    "            f.write(f\"  Average HD95: {np.mean(hd95_list):.2f} mm (n={len(hd95_list)})\\n\" if hd95_list else f\"  Average HD95: N/A (n=0)\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 1. Configuration parameters\n",
    "    config = {\n",
    "        \"image_dir\": \"/workspace/Task04_Hippocampus/imagesTr\",\n",
    "        \"label_dir\": \"/workspace/Task04_Hippocampus/labelsTr\",\n",
    "        \"model_path\": \"/workspace/ct_models/best_model_27.pth\",\n",
    "        \"root_output_dir\": \"model_results_test\",  # Root output directory\n",
    "        \"spacing\": (0.5, 0.5, 5),          # Image spacing\n",
    "        \"batch_size\": 1,\n",
    "        \"num_workers\": 4\n",
    "    }\n",
    "    \n",
    "    # 2. Create directory structure\n",
    "    os.makedirs(config[\"root_output_dir\"], exist_ok=True)\n",
    "    summary_path = os.path.join(config[\"root_output_dir\"], \"global_summary.txt\")\n",
    "    \n",
    "    # 3. Device configuration\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # 4. Check if directories exist\n",
    "    print(f\"Checking if image directory exists: {os.path.exists(config['image_dir'])}\")\n",
    "    print(f\"Checking if label directory exists: {os.path.exists(config['label_dir'])}\")\n",
    "    \n",
    "    if not os.path.exists(config['image_dir']):\n",
    "        print(f\"ERROR: Image directory does not exist: {config['image_dir']}\")\n",
    "        return\n",
    "    if not os.path.exists(config['label_dir']):\n",
    "        print(f\"ERROR: Label directory does not exist: {config['label_dir']}\")\n",
    "        return\n",
    "    \n",
    "    # 5. Data transformations\n",
    "    val_transform = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\"]),\n",
    "            EnsureChannelFirstd(keys=\"image\"),\n",
    "            EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "            ConvertToMultiChannel5Classesd(keys=\"label\"),\n",
    "            SpatialPadd(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                spatial_size=(64, 64, 64),  # (D, H, W) — divisible by 32\n",
    "                method=\"end\",\n",
    "            ),\n",
    "            NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 6. Load dataset\n",
    "    dataset = CustomCTDataset(\n",
    "        image_dir=config[\"image_dir\"],\n",
    "        label_dir=config[\"label_dir\"],\n",
    "        transform=val_transform\n",
    "    )\n",
    "    \n",
    "    if len(dataset) == 0:\n",
    "        print(\"ERROR: No data loaded! Please check:\")\n",
    "        print(f\"1. Image directory: {config['image_dir']}\")\n",
    "        print(f\"2. Label directory: {config['label_dir']}\")\n",
    "        print(\"3. File naming patterns\")\n",
    "        print(\"4. File extensions (.nii or .nii.gz)\")\n",
    "        return\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        num_workers=config[\"num_workers\"],\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    print(f\"Total patients to process: {len(dataset)}\")\n",
    "    \n",
    "    # 7. Initialize model\n",
    "    try:\n",
    "        model = SwinUNETR(\n",
    "            img_size=(192, 192, 192),  # Explicitly specify input size\n",
    "            in_channels=1,\n",
    "            out_channels=5,\n",
    "            feature_size=48,\n",
    "            use_checkpoint=True if torch.cuda.is_available() else False\n",
    "        ).to(device)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to initialize SwinUNETR with img_size=(192,192,192): {e}\")\n",
    "        print(\"Trying to initialize model without explicit img_size...\")\n",
    "        model = SwinUNETR(\n",
    "            in_channels=1,\n",
    "            out_channels=5,\n",
    "            feature_size=48,\n",
    "            use_checkpoint=True if torch.cuda.is_available() else False\n",
    "        ).to(device)\n",
    "    \n",
    "    # Load model weights (with error handling)\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(config[\"model_path\"], map_location=device))\n",
    "        print(\"Model loaded successfully with strict=True\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Warning: Strict loading failed: {e}\")\n",
    "        print(\"Trying non-strict loading...\")\n",
    "        model.load_state_dict(torch.load(config[\"model_path\"], map_location=device), strict=False)\n",
    "        print(\"Model loaded successfully with strict=False\")\n",
    "    model.eval()\n",
    "    \n",
    "    # Post-processing\n",
    "    post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "    \n",
    "    # 8. Inference + Visualization + Metrics calculation (process case by case)\n",
    "    all_metrics = {}  # Store metrics for all patients {patient_id: metrics}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "            patient_id = batch[\"patient_id\"][0]\n",
    "            print(f\"\\nProcessing patient {patient_id} ({idx+1}/{len(dataset)})\")\n",
    "            \n",
    "            # Create patient-specific directory\n",
    "            patient_dir = os.path.join(config[\"root_output_dir\"], patient_id)\n",
    "            os.makedirs(patient_dir, exist_ok=True)\n",
    "            \n",
    "            # Data preparation\n",
    "            image = batch[\"image\"].to(device)  # (1, 1, D, H, W)\n",
    "            label = batch[\"label\"].cpu().numpy()[0]  # (5, D, H, W)\n",
    "            original_image = image.cpu().numpy()[0, 0]  # (D, H, W) - original CT image\n",
    "            \n",
    "            # Model inference (with error handling for different ROI sizes)\n",
    "            try:\n",
    "                output = sliding_window_inference(\n",
    "                    inputs=image,\n",
    "                    roi_size=(64, 64, 64),\n",
    "                    sw_batch_size=1,\n",
    "                    predictor=model,\n",
    "                    overlap=0.5,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Sliding window with roi_size=(64,64,64) failed: {e}\")\n",
    "                print(\"Trying smaller roi_size=(32,32,32)...\")\n",
    "                try:\n",
    "                    output = sliding_window_inference(\n",
    "                        inputs=image,\n",
    "                        roi_size=(32, 32, 32),\n",
    "                        sw_batch_size=1,\n",
    "                        predictor=model,\n",
    "                        overlap=0.5,\n",
    "                    )\n",
    "                except Exception as e2:\n",
    "                    print(f\"Error: All sliding window attempts failed: {e2}\")\n",
    "                    continue\n",
    "            \n",
    "            output = post_trans(output).cpu().numpy()[0]  # (5, D, H, W)\n",
    "            \n",
    "            # Convert to single-channel labels (1-5=subtypes, 0=background)\n",
    "            pred_3d = np.argmax(output, axis=0) + 1\n",
    "            pred_3d[np.sum(output, axis=0) < 0.5] = 0\n",
    "            target_3d = np.argmax(label, axis=0) + 1\n",
    "            target_3d[np.sum(label, axis=0) < 0.5] = 0\n",
    "            \n",
    "            # Calculate quantitative metrics (only for subtypes present in labels)\n",
    "            metrics = EvaluationMetrics.calculate_all_metrics(\n",
    "                pred=pred_3d,\n",
    "                target=target_3d,\n",
    "                spacing=config[\"spacing\"]\n",
    "            )\n",
    "            \n",
    "            all_metrics[patient_id] = metrics\n",
    "            \n",
    "            # Generate visualization\n",
    "            vis_path = generate_visualization(\n",
    "                image_3d=original_image,\n",
    "                target_3d=target_3d,\n",
    "                pred_3d=pred_3d,\n",
    "                metrics=metrics,\n",
    "                patient_id=patient_id,\n",
    "                save_dir=patient_dir\n",
    "            )\n",
    "            \n",
    "            # Save detailed patient metrics\n",
    "            metrics_path = save_patient_metrics(patient_id, metrics, patient_dir)\n",
    "            \n",
    "            # Save prediction as nii file\n",
    "            nii_path = save_prediction_as_nii(\n",
    "                pred_3d=pred_3d,\n",
    "                patient_id=patient_id,\n",
    "                dataset=dataset,\n",
    "                save_dir=patient_dir\n",
    "            )\n",
    "            \n",
    "            print(f\"  Visualization saved to: {vis_path}\")\n",
    "            print(f\"  Metrics saved to: {metrics_path}\")\n",
    "            if nii_path:\n",
    "                print(f\"  Prediction saved to: {nii_path}\")\n",
    "    \n",
    "    # 9. Generate global summary file (with error handling for empty data)\n",
    "    if all_metrics:\n",
    "        update_summary_file(all_metrics, summary_path)\n",
    "        print(f\"\\nGlobal summary saved to: {summary_path}\")\n",
    "    else:\n",
    "        print(\"\\nWarning: No metrics to summarize (all_metrics is empty)!\")\n",
    "    \n",
    "    # 10. Output final statistics\n",
    "    print(\"\\n=== Processing Complete ===\")\n",
    "    print(f\"Total patients processed: {len(all_metrics)}\")\n",
    "    print(f\"Results stored in: {config['root_output_dir']}\")\n",
    "    if all_metrics:\n",
    "        print(f\"Each patient has:\")\n",
    "        print(f\"  - Visualization image: [ID]/[ID]_visualization.png\")\n",
    "        print(f\"  - Detailed metrics: [ID]/[ID]_metrics.txt\")\n",
    "        print(f\"  - Prediction nii: [ID]/[ID]_prediction.nii.gz\")\n",
    "        print(f\"Global summary: {summary_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc806bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7ce578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
